{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from src.datamodules.gmm_datamodule import feat_label_concat\n",
    "import numpy as np \n",
    "\n",
    "def gmm_generator(means):\n",
    "    dim=len(means[0])\n",
    "    num_gmm_source=len(means)\n",
    "    source_gmm = GaussianMixture(n_components=num_gmm_source)\n",
    "    source_gmm.weights_ = np.ones(num_gmm_source) / num_gmm_source\n",
    "    source_gmm.means_ = np.array(means)*1.2\n",
    "    source_gmm.covariances_ = [\n",
    "        np.eye(dim) * 0.03 for _ in range(num_gmm_source)\n",
    "    ]\n",
    "    feature, label = source_gmm.sample(500)\n",
    "    batch = feat_label_concat(feature, label)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Axis_Params():\n",
    "    def __init__(self, left_place, right_place, figsize=(10, 10), title='', label_font_size=15, axis_font_size=15, title_font_size=22, opacity=1, scatter_size=20, new_fig=True, bandwidth_kde=0.9, num_grid=100):\n",
    "        self.left_place = left_place\n",
    "        self.right_place = right_place\n",
    "        self.title = title\n",
    "        self.label_font_size = label_font_size\n",
    "        self.axis_font_size = axis_font_size\n",
    "        self.title_font_size = title_font_size\n",
    "        self.figsize = figsize\n",
    "        self.opacity = opacity\n",
    "        self.scatter_size = scatter_size\n",
    "        self.new_fig = new_fig\n",
    "        self.bandwidth = bandwidth_kde\n",
    "        self.num_grid = num_grid\n",
    "\n",
    "\n",
    "class Axis_Params_3d(Axis_Params):\n",
    "    def __init__(self, x_rotate=None, z_rotate=None, colors=None, xlabel=None, ylabel=None, zlabel=None, *kargs, **kwargs):\n",
    "        super(Axis_Params_3d, self).__init__(*kargs, **kwargs)\n",
    "        self.x_rotate = x_rotate\n",
    "        self.z_rotate = z_rotate\n",
    "        self.colors = colors\n",
    "        self.xlabel = xlabel\n",
    "        self.ylabel = ylabel\n",
    "        self.zlabel = zlabel\n",
    "\n",
    "\n",
    "def set_matplotlib_axis(ax, ax_params):\n",
    "    # ax.set_xlim(ax_params.left_place, ax_params.right_place)\n",
    "    # ax.set_ylim(ax_params.left_place, ax_params.right_place)\n",
    "    ax.tick_params(axis='both', which='major',\n",
    "                   labelsize=ax_params.axis_font_size)\n",
    "    ax.set_title(ax_params.title, fontsize=ax_params.title_font_size)\n",
    "    return ax\n",
    "\n",
    "def plt_scatter_3d_alone(sample_n_3_list, ax_params,path,num_total_class,x_bound=None,y_bound=None,z_bound=None):\n",
    "    fig = plt.figure(figsize=ax_params.figsize)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    cmap = plt.get_cmap(\"jet\")\n",
    "    for sample_n_3 in sample_n_3_list:\n",
    "        ax.scatter(sample_n_3[:, 0], sample_n_3[:, 1],\n",
    "                sample_n_3[:, 2], alpha=ax_params.opacity, s=ax_params.scatter_size,\n",
    "                c=cmap(sample_n_3[:, -1] / num_total_class),)\n",
    "    set_matplotlib_axis(ax, ax_params)\n",
    "    ax.view_init(elev=ax_params.x_rotate, azim=ax_params.z_rotate)\n",
    "    # you will need this line to change the Z-axis\n",
    "    ax.autoscale(enable=False, axis='both')\n",
    "    ax.grid(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zticks([])\n",
    "\n",
    "    ax.set_xbound(x_bound)\n",
    "    ax.set_ybound(y_bound)\n",
    "    ax.set_zbound(z_bound) # -1, 10.5\n",
    "    ax.set_xlabel(ax_params.xlabel)\n",
    "    ax.set_ylabel(ax_params.ylabel)\n",
    "    ax.set_zlabel(ax_params.zlabel)\n",
    "    plt.savefig(path, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# means_list=[\n",
    "#     [[14, 1, 10], [15, 1, 10], [14, 0, 10], [15, 0, 10]], \n",
    "#     [[1, -6, 0], [1, -7, 0]], \n",
    "#     [[0, 5, 0], [0, 4, 0], [-1, 4.5, 0]], \n",
    "#     [[-8.8, -4, 0], [-8, -4.2, 0], [-7.2, -3.9, 0]]]\n",
    "means_list=[\n",
    "    [[-2, -1, 10], [-1, -1, 10], [-2, 0, 10], [-1, 0, 10]], \n",
    "    [[1, -6, 0], [1, -7, 0]], \n",
    "    [[0, 5, 0], [0, 4, 0], [-1, 4.5, 0]], \n",
    "    [[-8.8, -4, 0], [-8, -4.2, 0], [-7.2, -3.9, 0]]]\n",
    "batch_list=[]\n",
    "num_class_list=[]\n",
    "num_total_class=0\n",
    "for means in means_list:\n",
    "    batch = gmm_generator(means)\n",
    "    batch[:,-1]+=num_total_class\n",
    "    num_class_list.append(len(means))\n",
    "    num_total_class+=len(means)\n",
    "    batch_list.append(batch)\n",
    "\n",
    "# --------- plot 3d ------------\n",
    "parameter = Axis_Params_3d(\n",
    "    left_place=-9, right_place=6, figsize=(10,10), opacity=0.3, scatter_size=5, x_rotate=20, z_rotate=-50)\n",
    "\n",
    "plt_scatter_3d_alone(batch_list, parameter, \"train_data.png\", num_total_class)\n",
    "\n",
    "# --------- plot 2d ------------\n",
    "# draw_data(\n",
    "#     batch_list,\n",
    "#     \"train_data.png\",\n",
    "#     num_total_class,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from src.otdd.pytorch.distance import DatasetDistance\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def barycentric_projection(source_ds, target_ds, batch_shape, num_target_class, device):\n",
    "    dist = DatasetDistance(\n",
    "        source_ds,\n",
    "        target_ds,\n",
    "        inner_ot_method=\"exact\",\n",
    "        inner_ot_debiased=True,\n",
    "        inner_ot_entreg=1e-2,\n",
    "        entreg=1e-2,\n",
    "        device=device,\n",
    "        λ_y=0.1,\n",
    "    )\n",
    "\n",
    "    # This coupling is calculated based on the subsampling of #[maxsamples] samples.\n",
    "    _, coupling, target_feat, target_hard_label = dist.distance(\n",
    "        maxsamples=batch_shape[0], return_coupling=True\n",
    "    )\n",
    "    coupling1 = (\n",
    "        torch.nan_to_num(coupling, nan=10.0, posinf=10.0, neginf=1e-5).abs() + 1e-4\n",
    "    )\n",
    "    coupling2 = coupling1 / coupling1.sum(axis=1, keepdims=True)\n",
    "    assert abs(coupling2.sum(axis=1).min() - 1.0) < 1e-3\n",
    "    coupling = coupling2\n",
    "\n",
    "    pf_feat = coupling @ target_feat\n",
    "    # OTDD solver reshapes features to a flat vector\n",
    "    pf_feat = pf_feat.reshape(batch_shape)\n",
    "    # OTDD solver is shifting target_hard_labels\n",
    "\n",
    "    target_hard_label -= target_hard_label.min()\n",
    "    target_soft_labels = F.one_hot(target_hard_label, num_target_class).float()\n",
    "    pf_probs = coupling @ target_soft_labels\n",
    "    assert abs(target_soft_labels.sum(axis=-1).min() - 1.0) < 1e-3\n",
    "    return pf_feat, pf_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pushforward data\n",
    "\n",
    "from src.otdd.pytorch.datasets import CustomTensorDataset\n",
    "\n",
    "pf_soft_label_list=[]\n",
    "pf_hard_label_list=[]\n",
    "src_ds=CustomTensorDataset([\n",
    "    torch.Tensor(batch_list[0][:,:-1]).float(),\n",
    "    torch.Tensor(batch_list[0][:,-1]).long()\n",
    "    ])\n",
    "for idx in range(1, len(batch_list)):\n",
    "    trg_label = torch.Tensor(batch_list[idx][:,-1]).long()\n",
    "    trg_ds=CustomTensorDataset([\n",
    "        torch.Tensor(batch_list[idx][:,:-1]).float(),\n",
    "        trg_label-trg_label.min()\n",
    "        ])\n",
    "    pf_feat, pf_probs= barycentric_projection(src_ds, trg_ds, src_ds.tensors[0].shape, trg_label.max()-trg_label.min()+1, \"cpu\")\n",
    "    pf_soft_label_list.append((pf_feat, pf_probs))\n",
    "    pf_hard_label_list.append((pf_feat, pf_probs.argmax(axis=-1).long()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.loss_zoo import mse_loss,label_cost\n",
    "w_inner_matrix=np.zeros([3,3])\n",
    "w_inner_outer=np.zeros([3])\n",
    "λ_y=0.1\n",
    "source_ds=CustomTensorDataset([\n",
    "    torch.Tensor(batch_list[0][:,:-1]).float(),\n",
    "    torch.Tensor(batch_list[0][:,-1]).long()\n",
    "    ])   \n",
    "\n",
    "for idx_i in range(1,4):\n",
    "    trg_label = torch.Tensor(batch_list[idx_i][:,-1]).long()\n",
    "    trg_ds=CustomTensorDataset([\n",
    "        torch.Tensor(batch_list[idx_i][:,:-1]).float(),\n",
    "        trg_label-trg_label.min()\n",
    "        ])\n",
    "    \n",
    "    dist = DatasetDistance(\n",
    "        source_ds,\n",
    "        trg_ds,\n",
    "        inner_ot_method=\"exact\",\n",
    "        inner_ot_debiased=True,\n",
    "        inner_ot_entreg=1e-2,\n",
    "        entreg=1e-2,\n",
    "        device=\"cpu\",\n",
    "        λ_y=λ_y,\n",
    "    )\n",
    "    # w_inner_outer[idx_i-1] = dist.distance()    \n",
    "    _ = dist.distance()\n",
    "    w2_matrix = dist.pwlabel_stats[\"dlabs\"] / 2      \n",
    "    mapped_feat1 = batch_list[0][:,:-1]\n",
    "    mapped_feat2 = pf_soft_label_list[idx_i-1][0]\n",
    "    mapped_labels1 = batch_list[0][:,-1]\n",
    "    mapped_probs2 = pf_soft_label_list[idx_i-1][1]\n",
    "    w_inner_outer[idx_i-1] = mse_loss(mapped_feat1, mapped_feat2) + λ_y*label_cost(w2_matrix, mapped_labels1, mapped_probs2)    \n",
    "    print( mse_loss(mapped_feat1, mapped_feat2), label_cost(w2_matrix, mapped_labels1, mapped_probs2)    )\n",
    "    for idx_j in range(1,4):\n",
    "        if idx_i !=idx_j:\n",
    "            trg_label = torch.Tensor(batch_list[idx_j][:,-1]).long()\n",
    "            another_trg_ds = CustomTensorDataset([\n",
    "                torch.Tensor(batch_list[idx_j][:,:-1]).float(),\n",
    "                trg_label-trg_label.min()\n",
    "                ])\n",
    "            \n",
    "            dist = DatasetDistance(\n",
    "                trg_ds,\n",
    "                another_trg_ds,\n",
    "                inner_ot_method=\"exact\",\n",
    "                inner_ot_debiased=True,\n",
    "                inner_ot_entreg=1e-2,\n",
    "                entreg=1e-2,\n",
    "                device=\"cpu\",\n",
    "                λ_y=0.1,\n",
    "            )\n",
    "            _ = dist.distance()\n",
    "            w2_matrix = dist.pwlabel_stats[\"dlabs\"] / 2       \n",
    "                \n",
    "            mapped_feat1 = pf_soft_label_list[idx_i-1][0]\n",
    "            mapped_feat2 = pf_soft_label_list[idx_j-1][0]\n",
    "            mapped_labels1 = pf_hard_label_list[idx_i-1][1]\n",
    "            mapped_probs2 = pf_soft_label_list[idx_j-1][1]\n",
    "            w_inner_matrix[idx_i-1,idx_j-1] = mse_loss(mapped_feat1, mapped_feat2)+ λ_y*label_cost(w2_matrix, mapped_labels1, mapped_probs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w_inner_matrix, w_inner_outer)\n",
    "from src.transfer_learning.gen_geodesic import get_best_interp_param\n",
    "best_weight=get_best_interp_param(\n",
    "                w_inner_outer, w_inner_matrix\n",
    "            )\n",
    "print(best_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.scripts.suff2insuff import identity_transform\n",
    "from src.transfer_learning.mix_transformation import barycenteric_map_mix\n",
    "from copy import deepcopy\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "def identity_transform(*args):\n",
    "    return args\n",
    "\n",
    "# barycenteric mapping directly from tuple data\n",
    "# \n",
    "weights=[[0.5,0,0.5], [0,0.5,0.5], [0.65,0.35,0], list(best_weight)]\n",
    "# weights=[list(best_weight)]\n",
    "total_data = deepcopy(batch_list)\n",
    "\n",
    "for weight in weights:\n",
    "    mix_feat, mix_probs = barycenteric_map_mix(pf_soft_label_list,np.array(weight),num_class_list[1:],\"cpu\",identity_transform)\n",
    "    catg = Categorical(probs=mix_probs)\n",
    "    pf_labels = catg.sample().reshape(-1, 1) + num_class_list[0]\n",
    "    # pf_labels=mix_probs.argmax(axis=-1)+num_class_list[0]\n",
    "    pf_batch = feat_label_concat(mix_feat, pf_labels)    \n",
    "    total_data.append(pf_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = Axis_Params_3d(\n",
    "    left_place=-9, right_place=6, \n",
    "    figsize=(10,10), opacity=0.5, scatter_size=5, x_rotate=25, z_rotate=10)\n",
    "\n",
    "plt_scatter_3d_alone(total_data, parameter, \"gen_geodesic.png\", num_total_class, x_bound=(-14,2), y_bound=(-9,6), z_bound=(-1, 10.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transfer_learning.mix_transformation import mixup\n",
    "projection_data = [total_data[-1]]\n",
    "tuple_batch = [(batch[:,:2], (batch[:,-1]-batch[:,-1].min()).long()) for batch in batch_list[1:]]\n",
    "mix_feat, mix_probs = mixup(tuple_batch, best_weight,num_class_list[1:],\"cpu\",identity_transform)\n",
    "\n",
    "catg = Categorical(probs=mix_probs)\n",
    "pf_labels = catg.sample().reshape(-1, 1) + num_class_list[0]\n",
    "pf_batch = feat_label_concat(mix_feat, pf_labels)    \n",
    "projection_data.append(pf_batch)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 3), facecolor=\"w\")\n",
    "cmap = plt.get_cmap(\"jet\")\n",
    "ax[0].scatter(\n",
    "    batch_list[0][:, 0],\n",
    "    batch_list[0][:, 1],\n",
    "    color=cmap(batch_list[0][:, -1]/(batch_list[0][:, -1].max()+1)),\n",
    "    alpha=0.5,\n",
    ")\n",
    "x_lims = (-3, -0.5)\n",
    "y_lims = (-2, 0.9)\n",
    "ax[0].set_xlim(x_lims)\n",
    "ax[0].set_ylim(y_lims)  \n",
    "# ax[0].set_yticks([])\n",
    "# ax[0].axis('off')  \n",
    "\n",
    "for idx_batch, batch in enumerate(projection_data):\n",
    "    random_idxes=torch.randperm(batch.shape[0])\n",
    "    batch=batch[random_idxes]   \n",
    "    ax[idx_batch+1].scatter(\n",
    "        batch[:, 0],\n",
    "        batch[:, 1],\n",
    "        color=cmap(batch[:, -1] / num_total_class),\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax[idx_batch+1].set_yticks([])\n",
    "\n",
    "    ax[idx_batch+1].set_xlim(x_lims)\n",
    "    ax[idx_batch+1].set_ylim(y_lims)    \n",
    "    # ax[idx_batch+1].axis('off')  \n",
    "plt.subplots_adjust(wspace=0.2, hspace=0)\n",
    "fig.savefig(\"mixup_vs_projection.png\", bbox_inches=\"tight\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- 2d plots ----------\n",
    "def draw_data(\n",
    "    data_list,\n",
    "    fig_path,\n",
    "    num_total_class,\n",
    "    # plot_size=3,\n",
    "):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(13, 9), facecolor=\"w\")\n",
    "    cmap = plt.get_cmap(\"jet\")\n",
    "    for batch in data_list:\n",
    "        idxes=torch.randperm(batch.shape[0])\n",
    "        batch=batch[idxes]   \n",
    "        ax.scatter(\n",
    "            batch[:, 0],\n",
    "            batch[:, 1],\n",
    "            color=cmap(batch[:, -1] / num_total_class),\n",
    "            alpha=0.1,\n",
    "        )\n",
    "    # lims = (-plot_size, plot_size)\n",
    "    # ax.set_xlim(lims)\n",
    "    # ax.set_ylim(lims)\n",
    "    ax.axis('off')\n",
    "    fig.savefig(fig_path, bbox_inches=\"tight\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_data(\n",
    "    total_data,\n",
    "    \"mixup_vs_projection.png\",\n",
    "    num_total_class,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix=\"../logs/test/E2X_few_shot/EMNIST/\"\n",
    "postfix=\"_195000.png\"\n",
    "file_list=[\"FMNIST/source\",\"FMNIST/pushforward\",\"MNIST/pushforward\",\"USPS/pushforward\",\"KMNIST/pushforward\"]\n",
    "n_col=len(file_list)\n",
    "fig, axes = plt.subplots(n_col, 1, figsize=(13, 2 * n_col),dpi=200, facecolor=\"w\")\n",
    "for i, (file_name, ax) in enumerate(zip(file_list,axes.flatten())):\n",
    "    im=Image.open(prefix+file_name+postfix)\n",
    "    ax.imshow(im)\n",
    "    if i==0:\n",
    "        title = '$Q$'\n",
    "    else:\n",
    "        title = '$\\\\mathcal{T}_' + str(i) + '\\\\sharp Q$'\n",
    "    # r'{}'.format(title)\n",
    "    ax.set_ylabel(r'{}'.format(title), fontsize=20, rotation='horizontal', va=\"center\", labelpad=45,) #, color='limegreen')    \n",
    "    \n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "fig.tight_layout(pad=0.01)\n",
    "fig.savefig(\"EMNIST\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ternary plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transfer_learning.gen_geodesic import ternary_otdd_interpolation\n",
    "\n",
    "num_segment=6\n",
    "test_dataset_list = [\"MNIST\", \"EMNIST\", \"KMNIST\", \"USPS\", \"FMNIST\",]\n",
    "train_datasets_list = [\n",
    "    [\"EMNIST\", \"FMNIST\", \"USPS\"],\n",
    "    [\"MNIST\", \"FMNIST\", \"USPS\"],\n",
    "    [\"MNIST\", \"EMNIST\", \"USPS\"],\n",
    "    [\"MNIST\", \"EMNIST\", \"KMNIST\"],\n",
    "    [\"MNIST\", \"KMNIST\", \"USPS\"],\n",
    "    ]\n",
    "min_distance=1000 \n",
    "max_distance=0\n",
    "range_distance=0\n",
    "\n",
    "for test_dataset, train_datasets in zip(test_dataset_list, train_datasets_list):\n",
    "    target_alias = \"\".join(ds[0] for ds in train_datasets)    \n",
    "    otdd_path= f\"../logs/otdd_ternary_transport_metric/external_{test_dataset}/from_{test_dataset}2{target_alias}_repeat5.pth\"\n",
    "    otdd_stat= torch.load(otdd_path)\n",
    "    w2_vector_dict = otdd_stat[\"W(nu,mu_i)\"]\n",
    "    w2_matrix_dict = otdd_stat[\"W(mu_i,mu_j)\"]\n",
    "    \n",
    "    avg_w2_matrix = sum(w2_matrix_dict.values()) / len(w2_matrix_dict)\n",
    "    avg_w2_vector = sum(w2_vector_dict.values()) / len(w2_vector_dict)\n",
    "\n",
    "    otdd_distance = ternary_otdd_interpolation(\n",
    "        avg_w2_vector, avg_w2_matrix, num_segment\n",
    "    )\n",
    "    \n",
    "    range_distance=max(range_distance,max(otdd_distance.values()) - min(otdd_distance.values()))    \n",
    "    min_distance=min(min_distance,min(otdd_distance.values()))\n",
    "    max_distance=max(max_distance,max(otdd_distance.values()))\n",
    "print(min_distance,max_distance,range_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_accuracy=100\n",
    "max_accuracy=0\n",
    "range_accuracy=0\n",
    "\n",
    "method=\"otdd_map\"\n",
    "for test_dataset, train_datasets in zip(test_dataset_list, train_datasets_list):\n",
    "    target_alias = \"\".join(ds[0] for ds in train_datasets)    \n",
    "    accuracy_save_path = f\"../logs/generalized_geodesic/fine_tune_{test_dataset}/{method}/run/train_on_{target_alias}_epoch100_repeat5.pt\"\n",
    "    accuracy = torch.load(accuracy_save_path)\n",
    "    \n",
    "    range_accuracy=max(range_accuracy,max(accuracy.values()) - min(accuracy.values()))\n",
    "    min_accuracy=min(min_accuracy,min(accuracy.values()))\n",
    "    max_accuracy=max(max_accuracy,max(accuracy.values()))\n",
    "print(min_accuracy,max_accuracy, range_accuracy)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ternary\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 200\n",
    "\n",
    "def draw_ternary_heatmap(accuracies, num_segment, fig_path, train_ds, title=None, vmin=0, vmax=100, figsize=(4,4), coloarbar=True, cmap='viridis'):\n",
    "    fontsize = 10\n",
    "    matplotlib.rcParams[\"figure.figsize\"] = figsize\n",
    "\n",
    "    _, tax = ternary.figure(scale=num_segment)\n",
    "    # print(accuracies)\n",
    "    cb_kwargs = {\"shrink\": 0.8, \"pad\": 0.01, \"aspect\": 30, \"orientation\": \"horizontal\"}\n",
    "    \n",
    "    tax.heatmap(accuracies, style=\"t\", colorbar=coloarbar, cmap=cmap, cb_kwargs=cb_kwargs, vmin=vmin, vmax=vmax)\n",
    "    tax.boundary()\n",
    "\n",
    "    tax.right_corner_label(train_ds[0], fontsize=fontsize, position=(1.1,0.1,0))\n",
    "    tax.top_corner_label(train_ds[1], fontsize=fontsize)\n",
    "    tax.left_corner_label(train_ds[2], fontsize=fontsize, position=(-0.2,0.1,0))\n",
    "    if title is not None:\n",
    "        tax.set_title(\n",
    "            title,\n",
    "            y=1.2,\n",
    "            pad=-14,\n",
    "        )\n",
    "    tax.clear_matplotlib_ticks()\n",
    "    tax.get_axes().axis(\"off\")\n",
    "    # tax.set_axis_limits({'b': [67, 76], 'l': [24, 33], 'r': [0, 9]})\n",
    "    \n",
    "    tax.savefig(\n",
    "        fig_path,\n",
    "        facecolor=\"w\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transfer_learning.gen_geodesic import ternary_otdd_interpolation\n",
    "\n",
    "for idx, (test_dataset, train_datasets) in enumerate(zip(test_dataset_list, train_datasets_list)):\n",
    "    target_alias = \"\".join(ds[0] for ds in train_datasets)    \n",
    "    accuracy_save_path = f\"../logs/generalized_geodesic/fine_tune_{test_dataset}/{method}/run/train_on_{target_alias}_epoch100_repeat5.pt\"\n",
    "    accuracy = torch.load(accuracy_save_path)\n",
    "    \n",
    "    save_path = f\"ternary/{test_dataset}_acc.png\"\n",
    "    local_min_acc=min(accuracy.values())\n",
    "    local_max_acc=max(accuracy.values())\n",
    "    local_range=local_max_acc-local_min_acc\n",
    "    vmin=local_min_acc-(range_accuracy-local_range)*0.5\n",
    "    vmax=local_max_acc+(range_accuracy-local_range)*0.5\n",
    "    figsize=(2,2.2)\n",
    "    if idx< len(test_dataset_list)-1:\n",
    "        draw_ternary_heatmap(\n",
    "            accuracy,\n",
    "            num_segment,\n",
    "            save_path,\n",
    "            train_datasets,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            figsize=figsize,\n",
    "        )\n",
    "    else:\n",
    "        draw_ternary_heatmap(\n",
    "            accuracy,\n",
    "            num_segment,\n",
    "            save_path,\n",
    "            train_datasets,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            figsize=figsize,\n",
    "        )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transfer_learning.gen_geodesic import ternary_otdd_interpolation\n",
    "\n",
    "for idx, (test_dataset, train_datasets) in enumerate(zip(test_dataset_list, train_datasets_list)):\n",
    "    target_alias = \"\".join(ds[0] for ds in train_datasets)    \n",
    "    otdd_path= f\"../logs/otdd_ternary_transport_metric/external_{test_dataset}/from_{test_dataset}2{target_alias}_repeat5.pth\"\n",
    "    otdd_stat= torch.load(otdd_path)\n",
    "    w2_vector_dict = otdd_stat[\"W(nu,mu_i)\"]\n",
    "    w2_matrix_dict = otdd_stat[\"W(mu_i,mu_j)\"]\n",
    "    \n",
    "    otdd_dist_dict=[]\n",
    "    for key in w2_matrix_dict.keys():\n",
    "        otdd_dist_dict.append(ternary_otdd_interpolation(\n",
    "        w2_vector_dict[key], w2_matrix_dict[key], num_segment\n",
    "    ))\n",
    "    otdd_distance={}\n",
    "    for key in otdd_dist_dict[0].keys():\n",
    "        otdd_list=[dictionary[key] for dictionary in otdd_dist_dict]\n",
    "        otdd_distance[key]=sum(otdd_list)/len(otdd_list)\n",
    "\n",
    "    # avg_w2_matrix = sum(w2_matrix_dict.values()) / len(w2_matrix_dict)\n",
    "    # avg_w2_vector = sum(w2_vector_dict.values()) / len(w2_vector_dict)\n",
    "\n",
    "    # otdd_distance = ternary_otdd_interpolation(\n",
    "    #     avg_w2_vector, avg_w2_matrix, num_segment\n",
    "    # )\n",
    "    \n",
    "    local_min_dist=min(otdd_distance.values())\n",
    "    local_max_dist=max(otdd_distance.values())\n",
    "    local_range=local_max_dist-local_min_dist    \n",
    "    vmin=local_min_dist-(range_distance-local_range)*0.5\n",
    "    vmax=local_max_dist+(range_distance-local_range)*0.5\n",
    "    \n",
    "    save_path = f\"ternary/{test_dataset}_otdd.png\"\n",
    "        \n",
    "    if idx< len(test_dataset_list)-1:\n",
    "        draw_ternary_heatmap(\n",
    "            otdd_distance,\n",
    "            num_segment,\n",
    "            save_path,\n",
    "            train_datasets,\n",
    "            vmin=min_distance,\n",
    "            vmax=max_distance,\n",
    "            figsize=figsize,\n",
    "            cmap='viridis_r',\n",
    "        )\n",
    "    else:\n",
    "        draw_ternary_heatmap(\n",
    "            otdd_distance,\n",
    "            num_segment,\n",
    "            save_path,\n",
    "            train_datasets,\n",
    "            vmin=min_distance,\n",
    "            vmax=max_distance,\n",
    "            figsize=figsize,        \n",
    "            cmap='viridis_r',   \n",
    "        )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "prefix=\"ternary/\"\n",
    "postfix=\".png\"\n",
    "dataset_list = [\"MNIST\", \"EMNIST\", \"USPS\", \"FMNIST\", \"KMNIST\"]\n",
    "# MNIST, EMNIST, USPS, FMNIST, KMNIST\n",
    "fig, axes = plt.subplots(2, 5, figsize=(14, 4.5),dpi=200, facecolor=\"w\")\n",
    "fontsize=15\n",
    "\n",
    "for i, (ds_name) in enumerate(dataset_list):\n",
    "    im=Image.open(prefix+ds_name+\"_otdd\"+postfix)\n",
    "    axes[0,i].imshow(im)    \n",
    "    im=Image.open(prefix+ds_name+\"_acc\"+postfix)\n",
    "    axes[1,i].imshow(im)      \n",
    "    axes[1,i].set_xlabel(ds_name, fontsize=fontsize, rotation='horizontal', va=\"center\", labelpad=15)\n",
    "    \n",
    "for ax in axes.flatten():\n",
    "    # ax.get_xaxis().set_visible(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # ax.axis('off')     \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)    \n",
    "     \n",
    "label_pad=10\n",
    "\n",
    "# axes[0,0].set_ylabel(r'$\\mathcal{W}_{2,Q}^2(P_a,Q)$', fontsize=20, rotation='vertical', va=\"center\", labelpad=label_pad,)\n",
    "axes[0,0].set_ylabel(r'$\\mathcal{W}^2(P_a,Q)$', fontsize=fontsize, rotation='vertical', va=\"center\", labelpad=label_pad,)\n",
    "axes[1,0].set_ylabel(\"Test on      Accuracy\", fontsize=fontsize, rotation='vertical', va=\"center\", labelpad=label_pad,)\n",
    "axes[1,0].yaxis.set_label_coords(-0.05,0.25)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0)          \n",
    "fig.tight_layout(pad=0.01)\n",
    "fig.savefig(\"ternary\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('otdd-map-iDm_2ZWb-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "cbbddd773a5396d7045e4c6fc4385e628b905520e0d19d9780b52384e4342523"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
